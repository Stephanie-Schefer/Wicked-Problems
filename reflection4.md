# The Social Dilemma – A Netflix Original Documentary

When an application is free, such as social media, the individual user is the product. Social media demands their time in order to make a profit by selling these views to advertising companies. According to Jaron Lanier, a computer scientist and founding father of virtual reality, the product is “the gradual, slight, imperceptible change in your own behavior and perception.” The fact that software companies call the customers “users” is troublesome because the only other industry that uses this word to describe consumers is the illegal drug industry. Manipulation is built into the core of what social media is, as the goal is to keep you on the site for as long as possible so that they can continue to sell the user’s attention to the advertising companies. The algorithms are designed to make social media addictive. On some platforms, whenever users refresh the page there are new posts at the top. This creates positive intermediate reinforcement and forms an unconscious habit so that users feel the need to constantly keep checking for updates.
Advanced statistical machine-learning techniques are able to make accurate predictions from data (clicks, likes, engagement, what was viewed, how long it was viewed, etc) for how users will behave or engage with their sight. The AI “gets to know” the individual and becomes better at making predictions of what they need to see in order to stay on the social media site for longer. Remember, social media’s goal is to guarantee success for their true clients, the advertising companies. Even when users are not using the site, the algorithm is still running to try to get you to re-engage. The notifications that pop up are associated with posts that have a high score, either the user has interacted with the account, or they have spent time viewing posts from the account even if they did not directly engage with it. The feature to tag other users in posts was made as a guarantee that users would engage with the sight. It is engraved into human psychology that if a photo of the person is out there, they need to know what it is, but the notifications “cleverly” do not show the photo. Instead, the user has to go into the app to see the photo. 
Proprietary algorithms, or the algorithm that show posts that have the highest score, aim to show the most relevant results and can create echo chambers as a byproduct when used on social media platforms. An echo chamber is a filtering of results, so the users get a biased set of posts, ads, etc., only portraying one side of an issue. Confirmation bias is thus prevalent because all the information shown to users, while relevant to their past interactions, it does not show both sides of the story. Oftentimes, the posts that go viral are full of misinformation and originated from bots, or fake accounts. Unfortunately, fake news spreads 6 percent faster than real news on Twitter according to The Social Dilemma documentary. Hundreds of bots share the same post, it gets shared around, then “the news bounces around the walls of this echo chamber, simultaneously spreading the false information and keeping out any contradictory thoughts that go against said misinformation” (“Misinformation”). Users are under the false assumption that everyone thinks the same way they do because they never see any contrary information. Using data science to make decisions about what users want to see is taking away human choices and making society vulnerable to confirmation bias. Filters can be helpful to an extent, but with society being more polarized than ever, I am starting to question how much is too much with these online platforms. 

## Works Cited
“Misinformation on Social Media – Bots and Echo Chambers.” Cornell University, 30 Nov. 2016, blogs.cornell.edu/info2040/2016/11/30/misinformation-on-social-media-bots-and-echo-chambers/. 

The Social Dilemma. Directed by Jeff Orlowski, Exposure Labs, 2020. Netflix. www.netflix.com/title/81254224 
